{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-cac3f9fe-c8ec-4f9f-b26e-086d3fbb5cd1",
    "deepnote_cell_type": "text-cell-h1",
    "tags": []
   },
   "source": [
    "# I. Import Module, configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-cfe208f6-eb9c-4911-b395-cbb99c4b0e83",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2747,
    "execution_start": 1619017427852,
    "source_hash": "d7784bd8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) #round float\n",
    "plt.rcParams['figure.figsize'] = (8.5, 5)\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "sns.mpl.rc(\"figure\", figsize=(8.5,5))\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-238c6fe0-4cad-4ebf-b7e9-4793fec68606",
    "deepnote_cell_type": "text-cell-h1",
    "tags": []
   },
   "source": [
    "# II. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-08b9e9bf-fc32-488d-a4fe-4d95ff0322ab",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We start by acquiring the training and testing datasets into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-591696e6-a236-4cd4-882b-cb7f722f3024",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 34,
    "execution_start": 1619017430599,
    "source_hash": "2f5d1445",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/work/train.csv', low_memory=False)\n",
    "test_df = pd.read_csv('/work/test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-acb4727e-95dd-4fba-be59-2a4ae29c7f8a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# III. Qu'est-ce qu'un pipeline et pourquoi l'utiliser ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-7f9011fd-afc5-4e95-b66b-82bf0409e170",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Le constructor Pipeline de scikit-learn permet de \"chainer\" une série de transformeurs et d'estimateurs.\n",
    "Par exemple, si le modèle implique une sélection des features, une standardisation et ensuite une regression, ces trois étapes peuvent être encapsulées ensemble via une pipeline.\n",
    "\n",
    "**Avantages** : \n",
    "\n",
    "* plus de lisibilité\n",
    "* code réutilisable et facile à intégrer dans différents endroits du code\n",
    "* plus simple d'expérimenter avec plusieurs modèles\n",
    "* assure que chaque transformation de la données est exécutée dans le bonne ordre, et protège contre le data leakage pendant la cross-validation\n",
    "* possibilité d'utiliser un grid search sur tous les parameters de tous les transformeurs et estimateurs.\n",
    "* seulement besoin d'appeler la méthode fit et predict une fois sur la donnée pour fit l'entièrté des estimateurs.\n",
    "\n",
    "**Construction d'une pipepline**\n",
    "\n",
    "*Pipeline*\n",
    "\n",
    "Pour construire une Pipeline, on utilise on liste de (key, value) où la key est une chaine de caractères contenant le nom donné à l'étape, et où la value est le nom de l'objet estimateur.\n",
    " \n",
    " ```\n",
    "pipeline = Pipeline([\n",
    "    ('model1', LinearRegression()),\n",
    "    ('model2', SVC())\n",
    "])\n",
    "\n",
    " ```\n",
    "\n",
    "*make_pipeline*\n",
    "\n",
    " Il est aussi possible de construire une pipeline avec la fonction make_pipeline de scikit-learn. C'est en quelque sorte un raccourcis pour créer une pipeline qui peut prendre un nombre variable d'estimateurs et retourne une pipeline. Le nom donné à chaque étape est rempli automatiquement.\n",
    "\n",
    " ```\n",
    "make_pipeline(Binazer(), MultinomialNB())\n",
    "return => Pipeline(steps=[('Binarizer', Binarizer()), ('multinomialnb', MultinomialNB())])\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-65ee6ca8-ba32-433f-87fa-4d80aec250f0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# IV. Qu'est-ce qu'un transformer et pourquoi/comment l'utiliser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-d6fb852f-880b-4740-97f3-baf6ea2095a9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Un Transformer est un objet scikit-learn qui permet d'appliquer une transformation (encodage, normalisation, ...) sur un DataFrame. L'intérêt du Transformer est double.\n",
    "\n",
    "    - Pouvoir définir une méthode de transformation sur-mesure.\n",
    "    - Pouvoir appliquer cette méthode sur un DataFrame quelconque.\n",
    "\n",
    "il existe plusieurs transformer: \n",
    " \n",
    "*exemple :* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-1c72911d-eb55-4930-972f-77686baf6389",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**OrdinalEncoder :**  convertit les variables catégorielles en variables numériques : \n",
    "\n",
    "*exemple:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00027-6053ba6c-e871-43fd-b13e-4eb36cfc568d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 49,
    "execution_start": 1619017430633,
    "source_hash": "e4404105",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nenc = preprocessing.OrdinalEncoder()\\nX = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\\n\\nenc.fit(X)\\n\\nenc.transform([['female', 'from US', 'uses Safari']])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "\n",
    "enc.fit(X)\n",
    "\n",
    "enc.transform([['female', 'from US', 'uses Safari']])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-833a8d44-d266-4576-a3b8-19abd380281a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**OneHotEncoder:** pour les variables catégorielles, crée de nouvelles variables indiquant la présence de chaque valeur possible à partir des données d'origine. \n",
    "\n",
    "*exemple:*\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00029-a9933e4c-f6ff-4059-9361-361bed71d936",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 49,
    "execution_start": 1619017430647,
    "source_hash": "160c5a3e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\none_hot_encoder = Pipeline(\\n\\n  steps=[\\n\\n    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\\n\\n  ]\\n\\n)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "one_hot_encoder = Pipeline(\n",
    "\n",
    "  steps=[\n",
    "\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "\n",
    "  ]\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-9ada43e2-cea2-4f18-84a9-c03427f9e628",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "il est également possible de construire un Transformer sur mesure avec FunctionTransformer. En particulier, pour certaines variables explicatives pour lesquelles il n'est pas nécessaire d'utiliser un OneHotEncode.\n",
    "\n",
    "*exemple :* \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00031-aad21386-dc68-4e90-915f-13c903738c18",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 51,
    "execution_start": 1619017430659,
    "source_hash": "f6b82d5e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nencoding = { \"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3 }\\n\\ndef grad_encoder(df):\\n\\n  for col in df.columns:\\n\\n    df[col] = df[col].apply(lambda x: encoding[x])\\n\\n  return df\\n\\neval_encoder = Pipeline(\\n\\n  steps=[\\n\\n    (\\'grad\\', FunctionTransformer(grad_encoder))\\n\\n  ]\\n\\n)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "encoding = { \"low\": 0, \"med\": 1, \"high\": 2, \"vhigh\": 3 }\n",
    "\n",
    "def grad_encoder(df):\n",
    "\n",
    "  for col in df.columns:\n",
    "\n",
    "    df[col] = df[col].apply(lambda x: encoding[x])\n",
    "\n",
    "  return df\n",
    "\n",
    "eval_encoder = Pipeline(\n",
    "\n",
    "  steps=[\n",
    "\n",
    "    ('grad', FunctionTransformer(grad_encoder))\n",
    "\n",
    "  ]\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-90ba9005-dbd9-46c9-adf6-4025431c72be",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "ou pour des cas particuliers (exemple : si la valeur 5more est présente dans une colonne. Si seule la valeur numérique est intressante, il faudra construire un transformer sur mesure. C'est à dire une fonction qui sera appliquée à la colonne).\n",
    "\n",
    "*exemple:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00033-8c0d316c-7936-44cf-87e9-1466677bcaca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1619017430699,
    "source_hash": "4d479ff6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef num_encoder(df):\\n\\n  for col in df.columns:\\n\\n    df[col] = df[col].apply(lambda x: 5 if x == \"5more\" else x)\\n\\n    df[col] = df[col].apply(lambda x: 6 if x == \"more\" else x)\\n\\n  return df\\n\\n\\nnum_encoder = Pipeline(\\n\\n  steps=[\\n\\n    (\\'num\\', FunctionTransformer(num_encoder))\\n\\n  ]\\n\\n)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def num_encoder(df):\n",
    "\n",
    "  for col in df.columns:\n",
    "\n",
    "    df[col] = df[col].apply(lambda x: 5 if x == \"5more\" else x)\n",
    "\n",
    "    df[col] = df[col].apply(lambda x: 6 if x == \"more\" else x)\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "num_encoder = Pipeline(\n",
    "\n",
    "  steps=[\n",
    "\n",
    "    ('num', FunctionTransformer(num_encoder))\n",
    "\n",
    "  ]\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-b34d7099-1fb0-4907-ac00-3a035ccc1cf3",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Une fois terminé, il ne restera plus qu'à combiner tous ces Transformers dans un ColumnTransformer : cela va permettre d'appliquer chaque Transformer sur un ensemble de colonnes sur-mesure. \n",
    "Plutôt que d'écrire un Transformer par colonne, cela permet de gagner du temps en appliquant la même méthode d'encodage sur plusieurs colonnes.\n",
    "\n",
    "*exemple:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00035-dfd889a4-3649-493f-b218-2524b8b6cb77",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1619017430699,
    "source_hash": "5e612dc1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.compose import ColumnTransformer\\n\\n\\npreprocessor = ColumnTransformer(\\n\\n  transformers=[\\n\\n    ('categorical', one_hot_encoder, ['lug_boot', 'safety']),\\n\\n    ('grad', eval_encoder, ['buying', 'maint']),\\n\\n    ('num', num_encoder, ['doors', 'persons']),\\n\\n  ]\\n\\n)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "\n",
    "  transformers=[\n",
    "\n",
    "    ('categorical', one_hot_encoder, ['lug_boot', 'safety']),\n",
    "\n",
    "    ('grad', eval_encoder, ['buying', 'maint']),\n",
    "\n",
    "    ('num', num_encoder, ['doors', 'persons']),\n",
    "\n",
    "  ]\n",
    "\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-2792e5fa-c150-48b9-88bf-176871dadf9e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# V. Un estimator en machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00037-b9622d5f-1809-4c42-8eec-39ace450bf4e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Dans Scikit-learn, un estimator est un objet (classifieur) qui implémente la méthode fit(X, y) pour estimer un modèle et predict(T) afin d’utiliser ce modèle pour prendre des décisions (faire des prédictions). IL possède une grille d'hyper-paramètres (parm_grid)et un itérateur de validations croisés (CV). Le paramètre parm_grid est un dictionnaire (ou une liste de dictionnaires) dont les clées sont les noms des hyper-paramètres à faire varier et les valeurs associées sont des listes de valeurs à tester.   \n",
    "\n",
    "** Les différentes étapes dans l'utilisation d'un estimator: **\n",
    " * choisir les variables à tester et la variable cible (X et y)\n",
    " * l’ensemble de données peut être modifié de manière à ce qu’un pourcentage puisse être utilisé pour la formation du modèle et le reste pour les tests (train_test_split())\n",
    " * choisir un model (ex: regression logistique)\n",
    " * choisir les hyper-paramètres\n",
    " * fitter le modèle\n",
    " * appliquer le modèle sur les données de test.Dans le cas d'un apprentissage supervisé, utilisation de la fonction predict() pour avoir une prédiction. POur un apprentissage non supervisé, utilsiation de predict() ou transform pour déduire la variable cible\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-b5902382-8b28-484a-a242-74c4632674a1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# VI. Application sur les données Titanic: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-51573798-2000-4099-a491-8b2262d5f81a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**a ) Entrainement sur une partie des données et validation sur une autre **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00040-18665a41-5a1d-428b-a1d8-ad8da2cd0ce2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1009,
    "execution_start": 1619017430703,
    "source_hash": "4a54de7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# variable cible\n",
    "y = train_df[\"Survived\"]\n",
    "\n",
    "#variables explicatives \n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = train_df[features]\n",
    "\n",
    "# utilisation du tranformer OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# modèle avec les hyper-paramètres (ici, randomforest: apprentissage supervisé)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "\n",
    "#Pipeline \n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "\n",
    "# train_test_split pour définir un pourcentage pour l'entrainement et le reste pour les test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "\n",
    "# fitter le modèle\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# prédire \n",
    "predictions = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-91d7e620-2636-4f01-950c-f6aa664c5f20",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**a ) Entrainement l'ensemble des données **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00042-1a93be89-187f-4977-83b0-cd72fd28b8da",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 192,
    "execution_start": 1619017431726,
    "source_hash": "998f971e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# variable cible\n",
    "y = train_df[\"Survived\"]\n",
    "\n",
    "#variables explicatives \n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = train_df[features]\n",
    "\n",
    "# définition des variables utilisées pour la prediction\n",
    "X_test = test_df[features]\n",
    "\n",
    "# utilisation du tranformer OneHotEncoder\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, features)\n",
    "    ]\n",
    ")\n",
    "# modèle avec les hyper-paramètres (ici, randomforest: apprentissage supervisé)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\n",
    "\n",
    "#Pipeline \n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# fitter le modèle\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# prédire \n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=afb2cb51-127c-46d5-8892-aab192039534' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "0f3d945a-2c46-4651-bdd3-a2a44609c21d"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
